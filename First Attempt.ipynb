{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove NaN values in question2 column\n",
    "data = data.ix[data.question2.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get english stopwords from nltk package\n",
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import useful libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to return data of specific column\n",
    "def get_question(data, column):\n",
    "    return data.loc[:,column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipeline to process data + classifiction training\n",
    "rf_pipeline = Pipeline([\n",
    "                # first process question1 and question2 independently\n",
    "                ('union', FeatureUnion([\n",
    "                            # process question1\n",
    "                            ('process_q1', Pipeline([\n",
    "                                            # get data from column 'question1'\n",
    "                                            ('get_q1', FunctionTransformer(get_question,\n",
    "                                                                           kw_args={'column':'question1'},\n",
    "                                                                           validate=False)),\n",
    "                                            # CountVectorizer + TfIdf with TfidfVectorizer\n",
    "                                            # stop_words from nltk data, max_features to use,\n",
    "                                            # and max_df to remove any repeating patterns that are not\n",
    "                                            # capture by stop_words\n",
    "                                            ('vectorizer1', TfidfVectorizer(stop_words=stops, \n",
    "                                                                            max_features=100,\n",
    "                                                                            max_df=0.8))])),\n",
    "                            # do the same with 'question2' column\n",
    "                            ('process_q2', Pipeline([\n",
    "                                            ('get_q2', FunctionTransformer(get_question,\n",
    "                                                                           kw_args={'column':'question2'},\n",
    "                                                                           validate=False)),\n",
    "                                            ('vectorizer2', TfidfVectorizer(stop_words=stops, \n",
    "                                                                            max_features=100,\n",
    "                                                                            max_df=0.8))]))])),\n",
    "                        # use the processed columns 'question1' and 'question2' to train a model\n",
    "                        ('clf', RandomForestClassifier(100, n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(data.ix[:,1:-1], data.ix[:,-1], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32min 34s, sys: 12.3 s, total: 32min 46s\n",
      "Wall time: 9min 3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('process_q1', Pipeline(steps=[('get_q1', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function get_question at 0x13b6f2ea0>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args={'column': 'question1'}, pass_y=False,\n",
       "   ...ators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train model using the pipeline\n",
    "rf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64762410624341504"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate logloss using the test set predictions by the pipeline object\n",
    "log_loss(y_test, rf_pipeline.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipeline to process data + classifiction training\n",
    "rf_pipeline = Pipeline([\n",
    "                # first process question1 and question2 independently\n",
    "                ('union', FeatureUnion([\n",
    "                            # process question1\n",
    "                            ('process_q1', Pipeline([\n",
    "                                            # get data from column 'question1'\n",
    "                                            ('get_q1', FunctionTransformer(get_question,\n",
    "                                                                           kw_args={'column':'question1'},\n",
    "                                                                           validate=False)),\n",
    "                                            # CountVectorizer + TfIdf with TfidfVectorizer\n",
    "                                            # stop_words from nltk data\n",
    "                                            # and max_df to remove any repeating patterns that are not\n",
    "                                            # captured by stop_words\n",
    "                                            ('vectorizer1', CountVectorizer(stop_words=stops, \n",
    "                                                                            max_df=0.8)),\n",
    "                                            # instead of deciding which features to keep let's\n",
    "                                            # try and keep first 100 components using NMF\n",
    "                                            ('nmf_1', NMF(100))])),\n",
    "                            # do the same with 'question2' column\n",
    "                            ('process_q2', Pipeline([\n",
    "                                            ('get_q2', FunctionTransformer(get_question,\n",
    "                                                                           kw_args={'column':'question2'},\n",
    "                                                                           validate=False)),\n",
    "                                            ('vectorizer2', CountVectorizer(stop_words=stops, \n",
    "                                                                            max_df=0.8)),\n",
    "                                            ('nmf_2', NMF(100))]))],\n",
    "                                         n_jobs=-1)),\n",
    "                # use the processed columns 'question1' and 'question2' to train a model\n",
    "                ('clf', RandomForestClassifier(100, n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 2s, sys: 12.2 s, total: 10min 14s\n",
      "Wall time: 14min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union', FeatureUnion(n_jobs=-1,\n",
       "       transformer_list=[('process_q1', Pipeline(steps=[('get_q1', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function get_question at 0x13b6f2ea0>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args={'column': 'question1'}, pass_y=False,\n",
       "  ...ators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train model using the pipeline\n",
    "rf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47304461401597586"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate logloss using the test set predictions by the pipeline object\n",
    "log_loss(y_test, rf_pipeline.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipeline to process data + classifiction training\n",
    "gb_pipeline = Pipeline([\n",
    "                # first process question1 and question2 independently\n",
    "                ('union', FeatureUnion([\n",
    "                            # process question1\n",
    "                            ('process_q1', Pipeline([\n",
    "                                            # get data from column 'question1'\n",
    "                                            ('get_q1', FunctionTransformer(get_question,\n",
    "                                                                           kw_args={'column':'question1'},\n",
    "                                                                           validate=False)),\n",
    "                                            # CountVectorizer + TfIdf with TfidfVectorizer\n",
    "                                            # stop_words from nltk data\n",
    "                                            # and max_df to remove any repeating patterns that are not\n",
    "                                            # captured by stop_words\n",
    "                                            ('vectorizer1', CountVectorizer(stop_words=stops, \n",
    "                                                                            max_df=0.8)),\n",
    "                                            # instead of deciding which features to keep let's\n",
    "                                            # try and keep first 100 components using NMF\n",
    "                                            ('dim_red_1', NMF(100))])),\n",
    "                            # do the same with 'question2' column\n",
    "                            ('process_q2', Pipeline([\n",
    "                                            ('get_q2', FunctionTransformer(get_question,\n",
    "                                                                           kw_args={'column':'question2'},\n",
    "                                                                           validate=False)),\n",
    "                                            ('vectorizer2', CountVectorizer(stop_words=stops, \n",
    "                                                                            max_df=0.8)),\n",
    "                                            ('dim_red_2', NMF(100))]))],\n",
    "                                         n_jobs=-1)),\n",
    "                # use the processed columns 'question1' and 'question2' to train a model\n",
    "                ('clf', GradientBoostingClassifier(n_estimators=100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 35s, sys: 12.6 s, total: 8min 48s\n",
      "Wall time: 37min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('union', FeatureUnion(n_jobs=-1,\n",
       "       transformer_list=[('process_q1', Pipeline(steps=[('get_q1', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function get_question at 0x13b6f2ea0>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args={'column': 'question1'}, pass_y=False,\n",
       "  ...=100, presort='auto', random_state=None,\n",
       "              subsample=1.0, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train model using the pipeline\n",
    "gb_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58641317946014271"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate logloss using the test set predictions by the pipeline object\n",
    "log_loss(y_test, gb_pipeline.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cos_sim(X):\n",
    "    return cosine_similarity(X[0], X[1]).diagonal().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_questions_func(X,stops):\n",
    "    vectorizer = CountVectorizer(stop_words=stops)\n",
    "    vectorizer.fit(X['question1'])\n",
    "    return (vectorizer.fit_transform(X['question1']), vectorizer.transform(X['question2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debug_shape(X):\n",
    "    print(X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipeline to process data + classifiction training\n",
    "rf_pipeline = Pipeline([('preprocessing', FeatureUnion([('cos_sim', Pipeline([('process_questions', FunctionTransformer(process_questions_func,\n",
    "                                                                                                            kw_args={'stops':stops},\n",
    "                                                                                                            validate=False)),\n",
    "                                                                   ('cosine_sim', FunctionTransformer(get_cos_sim,validate=False))])),\n",
    "                                                                    # process question1 and question2 independently for NMF\n",
    "                                                        ('union', FeatureUnion([\n",
    "                                                                        # process question1\n",
    "                                                                        ('process_q1', Pipeline([\n",
    "                                                                                        # get data from column 'question1'\n",
    "                                                                                        ('get_q1', FunctionTransformer(get_question,\n",
    "                                                                                                                       kw_args={'column':'question1'},\n",
    "                                                                                                                       validate=False)),\n",
    "                                                                                        # CountVectorizer + TfIdf with TfidfVectorizer\n",
    "                                                                                        # stop_words from nltk data\n",
    "                                                                                        # and max_df to remove any repeating patterns that are not\n",
    "                                                                                        # captured by stop_words\n",
    "                                                                                        ('vectorizer1', CountVectorizer(stop_words=stops, \n",
    "                                                                                                                        max_df=0.8)),\n",
    "                                                                                         # instead of deciding which features to keep let's\n",
    "                                                                                        # try and keep first 100 components using NMF\n",
    "                                                                                        ('dim_red', NMF(100))\n",
    "                                                                                        ])),\n",
    "\n",
    "                                                                        # do the same with 'question2' column\n",
    "                                                                        ('process_q2', Pipeline([\n",
    "                                                                                        ('get_q2', FunctionTransformer(get_question,\n",
    "                                                                                                                       kw_args={'column':'question2'},\n",
    "                                                                                                                       validate=False)),\n",
    "                                                                                        ('vectorizer2', CountVectorizer(stop_words=stops, \n",
    "                                                                                                                        max_df=0.8)),\n",
    "                                                                                        ('dim_red', NMF(100))\n",
    "                                                                        ]))]))])),\n",
    "                        # use the processed columns 'question1' and 'question2' to train a model\n",
    "                        ('clf', RandomForestClassifier(100, n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# train model using the pipeline\n",
    "rf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# calculate logloss using the test set predictions by the pipeline object\n",
    "log_loss(y_test, rf_pipeline.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
